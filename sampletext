We’re seeing hundreds of CloudWatch metric and log-based alerts firing and resolving across CMCv2 for the last 2 days. This doesn’t appear to be an actual app issue — it’s coming from Grafana’s backend.

Error traces show:

pq: remaining connection slots are reserved for superuser connections
pq: too many clients already

This indicates Grafana’s PostgreSQL connection pool is exhausted, causing alert queries to fail temporarily. When Grafana can’t run its queries, it reports “Error” → triggers alerts → then resolves once connections free up.

We’ve confirmed it’s platform-side, not Lambda/ALB/API/DynamoDB-related. The fix will likely involve increasing DB connection limits or staggering alert evaluations on the Grafana side.