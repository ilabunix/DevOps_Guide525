✅ 1. “Why can’t this be done using the Knowledge Base in LPP?”

Here is a clean, clear, defensible answer:

The LPP Knowledge Base requires content owners to manually convert documents into PDF format and upload them into a separate storage location.

Our operational documentation already lives in Confluence, which is the system of record for playbooks, runbooks, and incident procedures across CloudOps.

Using LPP for this use case would introduce content duplication, version drift, and additional operational overhead for every future update.

The GenAI assistant needs to index the live Confluence pages so that responses are based on the most current, authoritative documentation.

In short:
	•	LPP KB = static PDFs + manual uploads
	•	Our Use Case = dynamic Confluence pages + automatic re-indexing

Because accuracy during incidents is critical, indexing the authoritative source (Confluence) is the safer and more maintainable approach.

⸻

✅ 2. SCOPE — Strengthened Version

Develop and validate a GenAI-powered assistant that provides operational troubleshooting guidance for on-prem and cloud applications using existing Confluence-based runbooks and playbooks.
The assistant will:
	•	Retrieve answers directly from Confluence using RAG-based indexing.
	•	Support engineers with step-by-step resolution guidance during incidents.
	•	Reduce MTTR by minimizing time spent searching through documentation.
	•	Provide a centralized chat interface accessible from AWS Console or Teams.

Target Users: Cloud Engineers, SREs, TechOps, and ADT members involved in incident response.

While the initial scope focuses on incident resolution, the underlying architecture is designed for expansion to proactive alerting, compliance workflows, and broader FRB operational documentation.

⸻

✅ 3. BUSINESS NEED — With Before/After Comparison

Amanda asked: “Focus on business process and show before/after improvement.”

Here is the refined version:

Today, engineers must manually search across Confluence, logs, dashboards, and historical tickets to resolve production issues.
This process is fragmented, time-consuming, and inconsistent, especially during high-pressure incidents.

Current State (Before):
	•	8–20 minutes spent locating the correct runbook or past incident notes.
	•	High variance in troubleshooting steps between engineers.
	•	Tribal knowledge often required to identify the right procedure.
	•	MTTR increases due to manual lookup and context switching.

Future State (After GenAI Assistant):
	•	Answers retrieved instantly from Confluence via natural language queries.
	•	Consistent, standardized responses based on approved runbooks.
	•	Engineers no longer need to search multiple systems.
	•	MTTR improvement target: 10–25% reduction for incidents supported by documented procedures.

A GenAI assistant directly addresses these inefficiencies by centralizing knowledge retrieval and providing expert-quality guidance at the moment it’s needed.

⸻

✅ 4. BUSINESS VALUE / BENEFITS (Incl. Measurements)

Amanda asked for “quantified benefits” and “a measurement plan.”

Here is a polished version:

Immediate Benefits
	•	Accelerated Incident Response
Typical search time for runbooks: 8–20 minutes → reduced to <30 seconds.
Measurement: Track MTTR for incidents where the assistant was used vs. not used.
	•	Operational Consistency
Reduces variance in troubleshooting steps across engineers.
Measurement: % of incidents resolved using standardized procedures.
	•	Faster Onboarding
New engineers gain faster access to institutional knowledge.
Measurement: Time-to-productivity for new hires decreases by an estimated 15–20%.

Future Benefits
	•	Improved System Reliability
Consistent troubleshooting reduces repeated outages caused by incorrect steps.
	•	Cross-Platform Expansion
Architecture supports onboarding of additional systems beyond CloudOps.
	•	Knowledge Preservation
Critical SME knowledge becomes systematized and searchable.

System-Level Impact
	•	Unified Incident Response Framework
Creates a standardized, FRB-wide model for operational knowledge access.
	•	Reduced Operational Risk
Less dependency on individual expertise lowers the risk of incorrect or delayed responses.
	•	Improved Workforce Efficiency
Estimated savings: 30–50 engineer-hours per month in reduced search and manual lookup time.

⸻

✅ 5. RISKS & MITIGATIONS — Clean Version

Risk 1: AI responses may use outdated or stale Confluence content.
Mitigation: Scheduled content refresh every X hours + version tagging.

Risk 2: Access to restricted Confluence spaces could unintentionally be indexed.
Mitigation: Confluence API token scoped to only approved spaces; IAM role boundaries enforced in Lambda.

Risk 3: Lack of adoption from engineers.
Mitigation: Conduct pilot sessions and measure improvement in MTTR to demonstrate value.

⸻

✅ 6. FUNDING REQUEST — Clean & Minimal Version

One-time Development Effort (internal): ~$20,000
AWS Runtime (Bedrock, OpenSearch, Lambda, API Gateway): $300/month ($3,600/year)
Annual Maintenance (refresh, monitoring, re-indexing): ~$5,000

Total First-Year Cost: ~$28,600
Subsequent Years: ~$8,600 annually
