ğŸ¤ CloudOps Chatbot â€“ POC Presentation Script

â¸»

ğŸ”¹ Opening

â€œHi everyone, today Iâ€™m excited to walk you through a Proof of Concept Iâ€™ve developed called Ask Clara â€“ Your CloudOps Assistant.
Clara is a GenAI-powered chatbot built for operational teams. It helps engineers get instant, contextual answers from our Confluence-based playbooks and documentation â€“ without having to dig around manually during critical incidents.â€

â¸»

ğŸ”¹ Objective

â€œThe goal of this POC was to prove that we could use AWS-native services to create a smart assistant that understands operational questions and answers them using our own internal runbooks, securely and reliably.â€

â¸»

ğŸ”¹ Architecture Overview

â€œLet me walk you through how this works end-to-end.â€

You can refer to your diagram here, or describe it like this:

ğŸ§© Tech Stack (Layers)

1. User Interface Layer
	â€¢	Frontend: Static HTML/CSS/JS page hosted on S3 (or used locally for demo).
	â€¢	Interaction: The user types a question into a chat-style UI.

2. API & Invocation
	â€¢	API Gateway: Forwards user input as JSON over HTTPS.
	â€¢	Lambda Query Handler: Handles all logic for embedding the query, semantic search, and LLM invocation.

3. Embedding & Search Layer
	â€¢	Titan Embeddings (via Bedrock): Converts the input into a vector.
	â€¢	OpenSearch (Non-Serverless): Performs vector similarity search across indexed Confluence documents.

4. LLM & Answer Generation
	â€¢	Claude 3 Sonnet (via Bedrock): Generates the natural language answer based on the matched document.
	â€¢	Response Formatting: The Lambda packages the LLM response and returns it to the frontend.

5. Confluence Indexing
	â€¢	Scheduled Indexer Lambda: Runs twice a day to fetch new content from Confluence.
	â€¢	Tokenizer + Embedding: Breaks content into chunks and stores vectors in OpenSearch.

6. Monitoring
	â€¢	CloudWatch Logs + Alarms: For Lambda observability and error tracking.

â¸»

ğŸ”¹ Why Confluence?

â€œInstead of uploading files to S3, this POC connects directly to Confluence, so it indexes live operational content. This gives us real-time knowledge retrieval from trusted internal documentation.â€

â¸»

ğŸ”¹ Key Capabilities

â€œClara can answer questions like:
âœ”ï¸ â€˜How to restart EC2 using SSM?â€™
âœ”ï¸ â€˜What are the steps to rollback a Lambda deployment?â€™
âœ”ï¸ â€˜How to detect a DDoS event in AWS?â€™
And it provides answers with actual procedural steps pulled from our internal Confluence pages.â€

â¸»

ğŸ”¹ Demo Transition

â€œLetâ€™s jump into a quick demo. Iâ€™ll show you how a user interacts with Clara, what happens behind the scenes, and how the response is generated.â€

Walk through:
	â€¢	Asking a question on the UI
	â€¢	Showing the JSON API call
	â€¢	Briefly explaining the embedding + search logic
	â€¢	Returning to the answer in the UI

â¸»

ğŸ”¹ Future Enhancements

â€œHereâ€™s what weâ€™re looking to do next:â€

	â€¢	Role-based content filtering
	â€¢	Multi-turn chat memory
	â€¢	Feedback mechanism (â€œWas this helpful?â€)
	â€¢	Fallback to live Confluence fetch if needed

â¸»

ğŸ”¹ Closing

â€œThis POC proves that GenAI can enhance operational efficiency, reduce MTTR, and eliminate guesswork during incidents. Itâ€™s built fully with AWS-native services, scalable, and secure â€“ and it brings clarity to chaos, with Clara.â€